{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BoSdFRFMmZRy"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BYU CS 280 Tool Lab 2: Machine Learning Tools"
      ],
      "metadata": {
        "id": "_slaQdUGCB0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependencies for the lab\n",
        "import sklearn as sk\n",
        "#Preprocessing Packages\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#ML Algorithms\n",
        "import xgboost as xgb\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import ARDRegression\n",
        "from sklearn import svm\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Gaema31vjP8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction:\n",
        "\n",
        "### Scikit-learn\n",
        "Scikit-learn is a very popular library for machine learning in Python. You can think of it as an add-on to scipy/numpy with a very large number of implementations of common machine learning algorithms.\n",
        "\n",
        "In general, the scikit-learn API can help you accomplish the following tasks:\n",
        "* Preprocessing\n",
        "* Dimensionality Reduction\n",
        "* Clustering\n",
        "* Classification\n",
        "* Regression\n",
        "\n",
        "### XGBoost\n",
        "XGBoost stands for Extreme Gradient Boosting, which is a scalable, distributed gradient-boosted decision tree machine learning library. It provides parallel tree boosting and is the leading machine learning library for regression, classification, and ranking problems. It implements machine learning algorithms under the Gradient Boosting framework. It also provides parallel training capabilities so you can train your algorithms using multiple processors and gpus.\n",
        " "
      ],
      "metadata": {
        "id": "ct7fnkcnCL8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1: Preprocessing\n",
        "Very rarely will you be given perfect data, and this lab is no exception to the rule. In this section you will preprocess and prepare the datasets for testing various algorithms."
      ],
      "metadata": {
        "id": "qf46SalpGx8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieving the predicted values"
      ],
      "metadata": {
        "id": "k5pZF50M8MgC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using two different datasets in this lab, because we will be training both classification and regression algorithms. You'll be able to download them and read them by running the following cells."
      ],
      "metadata": {
        "id": "tgFiIwBvIlAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/michael-holland-dev/CS280/main/tool_labs/tool_lab_2/titanic_dataset.csv\n",
        "!wget https://raw.githubusercontent.com/michael-holland-dev/CS280/main/tool_labs/tool_lab_2/videogamesales_dataset.csv"
      ],
      "metadata": {
        "id": "p_plc-evMKv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df = pd.read_csv(\"titanic_dataset.csv\")\n",
        "video_game_df = pd.read_csv(\"videogamesales_dataset.csv\")"
      ],
      "metadata": {
        "id": "AMu97gb0OVBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets take a look at the titanic dataframe!"
      ],
      "metadata": {
        "id": "5M_BK4algSOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df.head()"
      ],
      "metadata": {
        "id": "Wh6OCzHCgRAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataframes above contain the features (X) and the labels (y). \n",
        "\n",
        "Whe you're training the algorithms on the Titanic dataset you will attempt to predict whether a person died or survived on the Titanic. Your features (X) should include some combination of the columns: `Pclass, Sex, Age, SibSp, Parch, Fare, and Embarked` and your label (y) should be the `Survived` column. \n",
        "\n",
        "For the videogame dataset you will attempt to predict the sales of videogames using the `Rank, Platform, Year, Genre, Publisher, and JP_Sales` columns and your expected output should be `Global_Sales`. \n",
        "\n",
        "Feel free to experiment with different combinations of columns in your datasets as that may affect your results in training the algorithms below. You may drop some features, add features. A lot of datascience is experimenting to see which columns have the best relationship for future predictions.\n",
        "\n",
        "In the cells below, you will select a subset of columns from the dataframes for the features (X value) and the labels (Y value). The titanic should have `Survived` as the label and the videogame dataset should have `Global_Sales` as the label.\n",
        "\n",
        "If you are unsure how to take a subset of a dataframe, review this [page](https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html) from the Pandas documentation"
      ],
      "metadata": {
        "id": "qOXLCHvQ9L7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create your Videogame & Titanic subsets below:\n",
        "titanic_X = #Assign a subset of Titanic columns as the features\n",
        "titanic_y = #Assign the survived column as the labels\n",
        "\n",
        "videogame_X = #Assign a subset of Videogame columns as the features\n",
        "videogame_y = #Assign the global_sales column as labels"
      ],
      "metadata": {
        "id": "Rx3Vw39C9Lua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Label Encoding\n",
        "We will need to encode the categorical word values from the datasets into numerical values. This is done so that the algorithms are able to effectively learn their features to be able to predict the labels with a high degree of accuracy.\n",
        "\n",
        "We will be using SKLearn's `LabelEncoding` tool which takes in categorical variables, and assigns them an integer value.\n",
        "\n",
        "Example code for the titanic dataset is shown below, but you will have to compute the label encodings for the videogame dataset."
      ],
      "metadata": {
        "id": "ruS5Sge57GRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Show the pre transformation results\n",
        "titanic_X.head()"
      ],
      "metadata": {
        "id": "7vgkBzZZBwFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the LabelEncoder Function\n",
        "label_encoder = LabelEncoder()\n",
        "#Apply the fit_transform function to every single column of the dataframe\n",
        "titanic_X = titanic_X.apply(label_encoder.fit_transform)\n",
        "#Show the post transformation results\n",
        "titanic_X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2301iD4fBNfq",
        "outputId": "34a11ce4-edf9-411b-e6fe-62284b8bdbf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Embarked\n",
              "0         0       2    1   28      1      0    18         2\n",
              "1         1       0    0   51      1      0   207         0\n",
              "2         1       2    0   34      0      0    41         2\n",
              "3         1       0    0   47      1      0   189         2\n",
              "4         0       2    1   47      0      0    43         2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50d0b969-dbae-4a94-a2a5-969952930402\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>207</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>189</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50d0b969-dbae-4a94-a2a5-969952930402')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-50d0b969-dbae-4a94-a2a5-969952930402 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-50d0b969-dbae-4a94-a2a5-969952930402');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now you do the same for the videogame dataset\n"
      ],
      "metadata": {
        "id": "3saxZRyNB2wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Hot Encoding\n",
        "Before training your regression algorithms on the videogame dataset, you should read this article on [One Hot Encoding](https://www.educative.io/blog/one-hot-encoding)\n",
        "\n",
        "For the video game dataframe, there are quite a few categorical variables, you should use the sklearn function for [one hot encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html). This will allow you represent the catagories in a numerical fashion. This will allow the regression algorithm to classify the data easier than it would with raw text.\n",
        "\n",
        "As before, we will show you how to do this for the titanic dataset then you have to do it for the videogame dataset."
      ],
      "metadata": {
        "id": "XWD7VgCuk17u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Before computing the labels, lets see the shape of the dataframe:\n",
        "print(titanic_X.shape)\n",
        "print(titanic_X.iloc[0])"
      ],
      "metadata": {
        "id": "zvm8oQ-OCTSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoder = OneHotEncoder()\n",
        "one_hot_encoder.fit(titanic_X)\n",
        "titanic_transformed = one_hot_encoder.transform(titanic_X).toarray()\n",
        "print(titanic_transformed.shape)\n",
        "print(titanic_transformed[0])"
      ],
      "metadata": {
        "id": "qgT3oGT2ly-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see from the first example, there are still 890 datapoints, but the one_hot_encoder converted all of the categorical data into numerical data.\n",
        "\n",
        "Now you need to convert the videogame data to one hot encodings in the cells below:"
      ],
      "metadata": {
        "id": "kWb-RutZCwP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#One hot encode the videogame data in the cell below:\n"
      ],
      "metadata": {
        "id": "ljiwQgWuQ8jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Split\n",
        "You will need to implement a train/test split function which will take in a percent number, and then returns four different values. The X_Train, the X_Test, the Y_Train, and the Y_Test. Where the test set is x% of the original data set, and the train set is 1-x%. So for example, if the dataset had 1000 individual data points, and we split it at 20%, the train set would have 800 data points, and the test set would have 200 data points. We recommend reading sklearn's [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to understand what it's supposed to do."
      ],
      "metadata": {
        "id": "LFEf3q_MDWof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(percent, X, y):\n",
        "  x_train = \n",
        "  x_test = \n",
        "  y_train = \n",
        "  y_test = \n",
        "  return ((x_train, x_test), (y_train, y_test))"
      ],
      "metadata": {
        "id": "7FT2XuQCDcPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the above train_test_split function above to split the two datasets with a 75/25 split (75% train, 25% test). You are *not* allowed to use sklearn's train_test_split function."
      ],
      "metadata": {
        "id": "KVTy-VucQ9dP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2: Classification\n",
        "XGBoost and Scikit Learn both have classification algorithms, in this section of the lab, you will train these algorithms using the titanic dataset and attempt to classify whether or not a given person survives based on their stats. You will use both the XGBoost classifiers as well as set of various SKLearn Classifiers.\n",
        "\n",
        "You can read the documentation for integrating xgboost with sklearn [here](https://xgboost.readthedocs.io/en/stable/python/examples/sklearn_parallel.html#sphx-glr-python-examples-sklearn-parallel-py)"
      ],
      "metadata": {
        "id": "BoSdFRFMmZRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the XGBClassifier\n",
        "xgboost_classifier = xgb.XGBClassifier()\n",
        "\n",
        "#Fit the data using the XGBClassifier.fit(X,y) function\n",
        "\n",
        "#Predict the classification using the XGBClassifier.predict(X_Test) function\n",
        "\n",
        "#Calculate the percent correct by using the accuracy_score function"
      ],
      "metadata": {
        "id": "dO75pKCMnkWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the XGBRF classifier\n",
        "xgboost_random_forest_classifier = xgb.XGBRFClassifier()\n",
        "\n",
        "#Fit the data using the same .fit(X,y) function\n",
        "\n",
        "#Predict the classification using the same .predict(X_Test) function \n",
        "\n",
        "#Calculate the percent correct by using the accuracy_score function"
      ],
      "metadata": {
        "id": "_wUCPFwrpa5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machine Classification [Documentation](https://scikit-learn.org/stable/modules/svm.html#classification)"
      ],
      "metadata": {
        "id": "GPBuNcgzqjbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the SKLearn SVM classifier\n",
        "supportVectorMachine = svm.SVC()\n",
        "\n",
        "#Fit the data using the same .fit(X,y) function\n",
        "\n",
        "#Predict the classification using the same .predict(X_Test) function \n",
        "\n",
        "#Calculate the percent correct by using the accuracy_score function"
      ],
      "metadata": {
        "id": "BP3iBMFZpwAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNeighbors Classification [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
        "* For this algorithm, do some hyperparameter tuning based on documentation above.\n",
        "* We'd recommend varying the number of neighbors, and see if that increases the performance of this algorithm"
      ],
      "metadata": {
        "id": "5Z_MS-pFq3f8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the SKLearn KNeighbor's classifier\n",
        "n = #Instantiate the number of neighbors\n",
        "kneighbors = KNeighborsClassifier(n)\n",
        "\n",
        "#Fit the data using the same .fit(X,y) function\n",
        "\n",
        "#Predict the classification using the same .predict(X_Test) function \n",
        "\n",
        "#Calculate the percent correct by using the accuracy_score function"
      ],
      "metadata": {
        "id": "6HsnstWPq-NA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi Layer Perceptron Classifier [Documentation](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#multi-layer-perceptron)\n",
        "* For this algorithm, do some hyperparameter tuning based on documentation above.\n",
        "* Vary the hiddenlayers, randomstate, and the alpha to see if that increases the perfomance of this algorithm."
      ],
      "metadata": {
        "id": "eFg6WShBrn7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_solver = #Enter solver\n",
        "custom_alpha = #Enter alpha\n",
        "custom_hidden_layer_sizes = #Enter hidden_layer_sizes\n",
        "custom_random_state = #Enter random_state\n",
        "multi_layer_perceptron_classifier = MLPClassifier(solver=custom_solver, alpha=custom_alpha, hidden_layer_sizes=custom_hidden_layer_sizes, random_state=custom_random_state)\n",
        "\n",
        "#Fit the data using the same .fit(X,y) function\n",
        "\n",
        "#Predict the classification using the same .predict(X_Test) function \n",
        "\n",
        "#Calculate the percent correct by using the accuracy_score function"
      ],
      "metadata": {
        "id": "-O2PasiVtH88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the given empirical results, explain below which machine learning algorithm would be best suited for prediciting whether a person would survive the titanic"
      ],
      "metadata": {
        "id": "dObwShaityKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Enter your results here)"
      ],
      "metadata": {
        "id": "rsKc1dcyt_ay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3: Regression\n",
        "In addition to classification, XGBoost and Scikit Learn also have regression algorithms. Regression algorithms are implemented when attempting to predict some sort of value such as temperature or a like count for a youtube video. In this section of the lab, you will train these algorithms using the video game sales dataset to predict the sales of a given title. You may have to feature engineer the data using the skills you gained in CS 180 and 280 to effectively predict the sales. You will compare a few different sklearn regression algorithms in this problem, as well as XGBoost regression algorithms."
      ],
      "metadata": {
        "id": "Bykl78pcuP3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the XGBRegressor\n",
        "xgboost_regressor = xgb.XGBRegressor()\n",
        "\n",
        "#Fit the data using the .fit(X,y) function\n",
        "\n",
        "#Predict the regression using the .predict(X_Test) function\n",
        "\n",
        "#Calculate the percent correct by using the .score(X,y) function"
      ],
      "metadata": {
        "id": "7LENhy24v6Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the XGBRFRegressor\n",
        "xgboost_rf_regressor = xgb.XGBRFRegressor()\n",
        "\n",
        "#Fit the data using the .fit(X,y) function\n",
        "\n",
        "#Predict the classification using the .predict(X_Test) function\n",
        "\n",
        "#Calculate the percent correct by using the .score(X,y) function"
      ],
      "metadata": {
        "id": "KfOUMIpYwQX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Isotonic Regression [Documenation](https://scikit-learn.org/stable/modules/generated/sklearn.isotonic.IsotonicRegression.html#sklearn.isotonic.IsotonicRegression)"
      ],
      "metadata": {
        "id": "MQYlvlIWwf-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the Isotonic Regressor\n",
        "isotonic_regression = IsotonicRegression()\n",
        "\n",
        "#Fit the data using the .fit(X,y) function\n",
        "\n",
        "#Predict the classification using the .predict(X_Test) function\n",
        "\n",
        "#Calculate the percent correct by using the .score(X,y) function"
      ],
      "metadata": {
        "id": "8EwNj-uLweZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)"
      ],
      "metadata": {
        "id": "5Vez2e1Wxsed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the Linear Regressor\n",
        "linear_regression = LinearRegression()\n",
        "\n",
        "#Fit the data using the .fit(X,y) function\n",
        "\n",
        "#Predict the regression using the .predict(X_Test) function\n",
        "\n",
        "#Calculate the percent correct by using the .score(X,y) function"
      ],
      "metadata": {
        "id": "riT4MeP3xsL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADR Bayseian Regressor [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ARDRegression.html#sklearn.linear_model.ARDRegression)\n",
        "* With this function do some hyperparameter tuning/a hyperparameter sweep to see which is the best for approximating.\n",
        "* There are too many parameters for this algorithm to write in this lab, so we recommend going to the documentation above to review the potential hyperparameters you can tune."
      ],
      "metadata": {
        "id": "0obYHLBsyOM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the Linear Regressor\n",
        "linear_regression = ARDRegression()\n",
        "\n",
        "#Fit the data using the .fit(X,y) function\n",
        "\n",
        "#Predict the classification using the .predict(X_Test) function\n",
        "\n",
        "#Calculate the percent correct by using the .score(X,y) function"
      ],
      "metadata": {
        "id": "ZcfUGVDry3vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the given empirical results, explain below which machine learning algorithm would be best suited for predicting sale prices for videogames."
      ],
      "metadata": {
        "id": "ZbnVVtHlznLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Enter your answer here)"
      ],
      "metadata": {
        "id": "gP48aOmfzvKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 4: Write Up\n",
        "Do some more additional research on how these algorithms work. We don't go super deep into the machine learning algorithms in this class because there's going to be a new class CS 270, which is an Introduction to Machine Learning, as well as CS 472, which is Machine Learning. Write 1-2 paragraphs explaining what you learned in this lab, as well as something you learned about your additional research that you did."
      ],
      "metadata": {
        "id": "Wy_-dlAw0CXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Enter your answer here)"
      ],
      "metadata": {
        "id": "mS41J4fl0EjJ"
      }
    }
  ]
}