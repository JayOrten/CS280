{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "3yNfkK0U8PRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFP8vIeS8J7E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import wandb\n",
        "from wandb.keras import WandbMetricsLogger\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# get your data\n",
        "(x_train, y_train), (x_val, y_val) = keras.datasets.cifar100.load_data()\n",
        "\n",
        "# constant values\n",
        "NUM_CLASSES = 100 #100 prediction classes\n",
        "INPUT_SHAPE = (32,32,3) #shape of the input image 32x32 with 3 channels\n",
        "\n",
        "# hyperparameters you will be tuning\n",
        "BATCH_SIZE = 50 \n",
        "EPOCHS = 5\n",
        "LEARNING_RATE = 1e-3\n",
        "L1NF = 16\n",
        "FDROPOUT = 0.5\n",
        "\n",
        "wandb.init(project = 'Tool Lab 3',\n",
        "          config={\n",
        "              'bs':BATCH_SIZE,\n",
        "              'lr':LEARNING_RATE,\n",
        "              'epochs': EPOCHS,\n",
        "              'l1nf':L1NF,\n",
        "              'fdr':FDROPOUT\n",
        "          },\n",
        "           name='RUN 0: L1NF 16 ' #this is your run name, please number your runs 0-n and tell what you changed\n",
        "          )\n",
        "\n",
        "# onehot encode your labels so your model knows its a category\n",
        "y_train = tf.one_hot(y_train,\n",
        "                     depth=y_train.max() + 1,\n",
        "                     dtype=tf.float64)\n",
        "y_val = tf.one_hot(y_val,\n",
        "                   depth=y_val.max() + 1,\n",
        "                   dtype=tf.float64)\n",
        "  \n",
        "y_train = tf.squeeze(y_train)\n",
        "y_val = tf.squeeze(y_val)\n",
        "\n",
        "# here is a basic model that you will add to\n",
        "model = tf.keras.models.Sequential([\n",
        "                  \n",
        "                  # CHANGE THESE: these are layers you should mix up and change\n",
        "                  layers.Conv2D(L1NF, (3, 3), input_shape = INPUT_SHAPE,\n",
        "                                activation='relu',\n",
        "                                padding='same'),\n",
        "                  layers.MaxPooling2D(2,2),\n",
        "                  layers.Dropout(FDROPOUT),\n",
        "                  \n",
        "                  # DO NOT CHANGE THESE. They should be at the end of your model\n",
        "                  layers.Flatten(),\n",
        "                  layers.Dense(NUM_CLASSES, activation='softmax')])\n",
        "\n",
        "\n",
        "# feel free to experiment with this\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=keras.optimizers.RMSprop(learning_rate=LEARNING_RATE),\n",
        "             # DO NOT CHANGE THE METRIC. This is what you will be judging your model on\n",
        "             metrics=['accuracy'],)\n",
        "\n",
        "\n",
        "# here you train the model using some of your hyperparameters and send the data\n",
        "# to weights and biases after every batch            \n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=EPOCHS,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=[WandbMetricsLogger(log_freq='batch')])"
      ]
    }
  ]
}